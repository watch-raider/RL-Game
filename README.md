# Human Feedback-Based Reinforcement Learning in Cooperative Environments

Currently working on this project for my Thesis in MSc Computer Science: Artificial Intelligence Specialisation

This thesis investigates the use of reinforcement learning (RL) to develop an agent capable of guiding a human to a specific goal location within an environment. 
In this cooperative setting, the agent has prior knowledge of the goal's location, while the human remains unaware and relies on the agent's guidance. 
Traditional RL focuses on agents learning optimal actions based on feedback from the environment, but this research integrates human feedback and interaction to enhance the guidance process.

The primary objective is to design an RL-based agent that learns to provide effective instructions or cues to the human, facilitating smooth navigation toward the goal. 
The humanâ€™s responses to the agent's guidance are used as feedback, helping the agent refine its strategy to adapt to the individual's actions and preferences. 
The research explores various approaches to improve the agent's ability to interpret human behavior and adjust its instructions dynamically, making the guidance more intuitive and efficient.

Challenges addressed include balancing clear communication with adaptability to human behavior, as well as optimizing the agent's strategy to ensure that the human can reach the goal as efficiently as possible. 
This research has applications in fields like human-robot interaction, virtual assistance, and autonomous systems, where collaborative goal achievement is critical.

## Plan

Initiallly implementing Q-learning algorithm and after evaulating the performance, will look to implement Deep Q-learning. Plan is to implement a number of techniques and compare 
perfomance for this specific task.
